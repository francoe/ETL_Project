{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pulling EIA storage data and population-weighted temperature outcomes\n",
    "Creates calls from the [Energy Information Administration's API](https://www.eia.gov/opendata/)\n",
    "and Climate Prediction Center's [FTP Site](ftp://ftp.cpc.ncep.noaa.gov/htdocs/degree_days/weighted/daily_data/)\n",
    "\n",
    "the EIA API series IDs used in this analysis are listed [here](https://www.eia.gov/opendata/qb.php?category=1709237)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import dependencies:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import datetime\n",
    "import json\n",
    "#import io\n",
    "#import urllib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Establish API key and organize a dictionary of API series id's for each storage region:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "eia_api_key = '9e4c8d5761a387405ed003e062d45727'\n",
    "\n",
    "#create dictionary \n",
    "eia_api_series_ids = {\n",
    "    'l48' : 'NG.NW2_EPG0_SWO_R48_BCF.W',\n",
    "    'east' : 'NG.NW2_EPG0_SWO_R31_BCF.W',\n",
    "    'midwest' : 'NG.NW2_EPG0_SWO_R32_BCF.W',\n",
    "    'mountain' : 'NG.NW2_EPG0_SWO_R34_BCF.W',\n",
    "    'pacific' : 'NG.NW2_EPG0_SWO_R35_BCF.W',\n",
    "    'south_central' : 'NG.NW2_EPG0_SWO_R33_BCF.W',\n",
    "    'salt' : 'NG.NW2_EPG0_SSO_R33_BCF.W',\n",
    "    'nonsalt': 'NG.NW2_EPG0_SNO_R33_BCF.W'\n",
    "}\n",
    "#establishes base url for the api call.\n",
    "#you just need to combine with the API ID string to complete each call\n",
    "base_url = f'http://api.eia.gov/series/?api_key={eia_api_key}&series_id='\n",
    "\n",
    "#establish a funcion that generates API calls\n",
    "def generate_call(n):\n",
    "    return json.loads(requests.get(base_url + eia_api_series_ids[n]).text)\n",
    "\n",
    "#establish a dictionaries that to save API calls and DataFrames\n",
    "call_dict = {}\n",
    "df_dict = {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create API calls:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in eia_api_series_ids:\n",
    "    call_dict[n] = generate_call(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**establish a function to generate API calls for each region:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_df(call):\n",
    "   return pd.DataFrame(call['series'][0]['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in call_dict:\n",
    "    df_dict[n] = generate_df(call_dict[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_df(n):\n",
    "    df_dict[n].columns=['week',f'{n}_inventory']\n",
    "    df_dict[n]['week'] = pd.to_datetime(df_dict[n]['week'])\n",
    "    df_dict[n] = df_dict[n].sort_values('week')\n",
    "    df_dict[n] = df_dict[n].set_index('week')\n",
    "    df_dict[n][f'{n}_change'] = df_dict[n][f'{n}_inventory'] - df_dict[n][f'{n}_inventory'].shift(1)\n",
    "    df_dict[n].index = df_dict[n].index - datetime.timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in df_dict:\n",
    "    format_df(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "eia_storage_data = df_dict['l48'].merge(\n",
    "    df_dict['east'], left_index = True, right_index = True).merge(\n",
    "    df_dict['midwest'], left_index = True, right_index = True).merge(\n",
    "    df_dict['mountain'], left_index = True, right_index = True).merge(\n",
    "    df_dict['pacific'], left_index = True, right_index = True).merge(\n",
    "    df_dict['south_central'], left_index = True, right_index = True).merge(\n",
    "    df_dict['salt'], left_index = True, right_index = True).merge(\n",
    "    df_dict['nonsalt'], left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weather Data Pull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pull HDDs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ = []\n",
    "for x in range(1981,datetime.datetime.now().year+1):\n",
    "    df = pd.read_csv(f'ftp://ftp.cpc.ncep.noaa.gov/htdocs/degree_days/weighted/daily_data/{x}/Population.Heating.txt',skiprows = 3, delimiter = '|').T\n",
    "    df.drop(df.index[0], inplace = True)\n",
    "    list_.append(df)\n",
    "CPC_HDDs = pd.concat(list_)\n",
    "CPC_HDDs.index = pd.to_datetime(CPC_HDDs.index)\n",
    "CPC_HDDs = CPC_HDDs[9]\n",
    "CPC_HDDs = pd.DataFrame(CPC_HDDs)\n",
    "CPC_HDDs.columns = ['HDDs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pull CDDs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ = []\n",
    "for x in range(1981,datetime.datetime.now().year+1):\n",
    "    df = pd.read_csv(f'ftp://ftp.cpc.ncep.noaa.gov/htdocs/degree_days/weighted/daily_data/{x}/Population.Cooling.txt',skiprows = 3, delimiter = '|').T\n",
    "    df.drop(df.index[0], inplace = True)\n",
    "    list_.append(df)\n",
    "CPC_CDDs = pd.concat(list_)\n",
    "CPC_CDDs.index = pd.to_datetime(CPC_CDDs.index)\n",
    "CPC_CDDs = CPC_CDDs[9]\n",
    "CPC_CDDs = pd.DataFrame(CPC_CDDs)\n",
    "CPC_CDDs.columns = ['CDDs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**create a single DataFrame for the weather data**\n",
    "\n",
    "...and add a Total Degree Day (TDDs) column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "CPC_TDDs = pd.merge(CPC_HDDs,CPC_CDDs, left_index = True, right_index = True)\n",
    "CPC_TDDs['TDDs'] = CPC_TDDs['HDDs'] + CPC_TDDs['CDDs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reample temperature data to report sum of degree days for each week ending Thursday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "CPC_TDDs_Weekly = CPC_TDDs.resample('W-Thu').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.merge(eia_storage_data,CPC_TDDs_Weekly, left_index = True, right_index = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
