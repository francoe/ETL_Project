{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Gas Storage and Temperature Outcomes\n",
    "\n",
    "This script pulls publicly available US temperature data and reported US natural gas storage activity, merges/formats that data using pandas DataFrames, and pushes the merged data to a SQL database\n",
    "\n",
    "Data is collected from the [Energy Information Administration's API](https://www.eia.gov/opendata/)\n",
    "and Climate Prediction Center's [FTP Site](ftp://ftp.cpc.ncep.noaa.gov/htdocs/degree_days/weighted/daily_data/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import dependencies:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import datetime\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Import SQL Alchemy\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Import and establish Base for which classes will be constructed \n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "Base = declarative_base()\n",
    "\n",
    "# Import modules to declare columns and column data types\n",
    "from sqlalchemy import Column, Integer, String, Float, Date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Establish API key and organize a dictionary of API series id's for each storage region:**\n",
    "_The EIA API series IDs used in this analysis are listed [here](https://www.eia.gov/opendata/qb.php?category=1709237)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "eia_api_key = 'YOUR_KEY_HERE'\n",
    "\n",
    "#this dictionary is a repository for the unique series ids for the Lower 48 and each EIA sub-region\n",
    "#... the regional keys established here are also referenced to establish dictionaries for the API calls and DataFrame conversions\n",
    "eia_api_series_ids = {\n",
    "    'l48' : 'NG.NW2_EPG0_SWO_R48_BCF.W',\n",
    "    'east' : 'NG.NW2_EPG0_SWO_R31_BCF.W',\n",
    "    'midwest' : 'NG.NW2_EPG0_SWO_R32_BCF.W',\n",
    "    'mountain' : 'NG.NW2_EPG0_SWO_R34_BCF.W',\n",
    "    'pacific' : 'NG.NW2_EPG0_SWO_R35_BCF.W',\n",
    "    'south_central' : 'NG.NW2_EPG0_SWO_R33_BCF.W',\n",
    "    'salt' : 'NG.NW2_EPG0_SSO_R33_BCF.W',\n",
    "    'nonsalt': 'NG.NW2_EPG0_SNO_R33_BCF.W'\n",
    "}\n",
    "\n",
    "#establishes base url for each API call\n",
    "#you just need to combine with the API ID string to complete each call\n",
    "base_url = f'http://api.eia.gov/series/?api_key={eia_api_key}&series_id='\n",
    "\n",
    "#establish empty dictionaries that will be used to save API calls and DataFrames\n",
    "call_dict = {}\n",
    "df_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create API calls:**\n",
    "\n",
    "_using a function that iterates through the regional names established in the keys for the eia_api_series_ids dictionary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_call(n):\n",
    "    return json.loads(requests.get(base_url + eia_api_series_ids[n]).text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in eia_api_series_ids:\n",
    "    call_dict[n] = generate_call(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert JSON data from the API calls to pandas DataFrames**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_df(call):\n",
    "   return pd.DataFrame(call['series'][0]['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in call_dict:\n",
    "    df_dict[n] = generate_df(call_dict[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Format the regional DataFrames**\n",
    "1. _name columns_\n",
    "2. _convert 'week' column to datetime format_\n",
    "3. _set the index to 'week'_\n",
    "4. calculate week-over-week inventory change for each week\n",
    "5. _subtract 1 day from the weekly index date, to reflect the actual end date of each 'gas week'_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_df(n):\n",
    "    df_dict[n].columns=['week',f'{n}_inventory']\n",
    "    df_dict[n]['week'] = pd.to_datetime(df_dict[n]['week'])\n",
    "    df_dict[n] = df_dict[n].sort_values('week')\n",
    "    df_dict[n] = df_dict[n].set_index('week')\n",
    "    df_dict[n][f'{n}_change'] = df_dict[n][f'{n}_inventory'] - df_dict[n][f'{n}_inventory'].shift(1)\n",
    "    df_dict[n].index = df_dict[n].index - datetime.timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in df_dict:\n",
    "    format_df(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "eia_storage_data = df_dict['l48'].merge(\n",
    "    df_dict['east'], left_index = True, right_index = True).merge(\n",
    "    df_dict['midwest'], left_index = True, right_index = True).merge(\n",
    "    df_dict['mountain'], left_index = True, right_index = True).merge(\n",
    "    df_dict['pacific'], left_index = True, right_index = True).merge(\n",
    "    df_dict['south_central'], left_index = True, right_index = True).merge(\n",
    "    df_dict['salt'], left_index = True, right_index = True).merge(\n",
    "    df_dict['nonsalt'], left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Weather Data Pull**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pull HDDs**\n",
    "\n",
    "*add note on HDD definition*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ = []\n",
    "for x in range(1981,datetime.datetime.now().year+1):\n",
    "    df = pd.read_csv(f'ftp://ftp.cpc.ncep.noaa.gov/htdocs/degree_days/weighted/daily_data/{x}/Population.Heating.txt',skiprows = 3, delimiter = '|').T\n",
    "    df.drop(df.index[0], inplace = True)\n",
    "    list_.append(df)\n",
    "CPC_HDDs = pd.concat(list_)\n",
    "CPC_HDDs.index = pd.to_datetime(CPC_HDDs.index)\n",
    "CPC_HDDs = CPC_HDDs[9]\n",
    "CPC_HDDs = pd.DataFrame(CPC_HDDs)\n",
    "CPC_HDDs.columns = ['HDDs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pull CDDs**\n",
    "\n",
    "*add note on CDD definition*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ = []\n",
    "for x in range(1981,datetime.datetime.now().year+1):\n",
    "    df = pd.read_csv(f'ftp://ftp.cpc.ncep.noaa.gov/htdocs/degree_days/weighted/daily_data/{x}/Population.Cooling.txt',skiprows = 3, delimiter = '|').T\n",
    "    df.drop(df.index[0], inplace = True)\n",
    "    list_.append(df)\n",
    "CPC_CDDs = pd.concat(list_)\n",
    "CPC_CDDs.index = pd.to_datetime(CPC_CDDs.index)\n",
    "CPC_CDDs = CPC_CDDs[9]\n",
    "CPC_CDDs = pd.DataFrame(CPC_CDDs)\n",
    "CPC_CDDs.columns = ['CDDs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Combine degree day data into a single datagrame**\n",
    "\n",
    "...and add a Total Degree Day (TDDs) column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "CPC_TDDs = pd.merge(CPC_HDDs,CPC_CDDs, left_index = True, right_index = True)\n",
    "CPC_TDDs['TDDs'] = CPC_TDDs['HDDs'] + CPC_TDDs['CDDs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resample temperature data to report sum of degree days for each week ending Thursday**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "CPC_TDDs_Weekly = CPC_TDDs.resample('W-Thu').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finally, combine all temperature and storage data into a single DataFrame**\n",
    "\n",
    "... _and convert all columns to integers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.merge(eia_storage_data,CPC_TDDs_Weekly, left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in combined_df.columns:\n",
    "    combined_df[n] = pd.to_numeric(combined_df[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l48_inventory</th>\n",
       "      <th>l48_change</th>\n",
       "      <th>east_inventory</th>\n",
       "      <th>east_change</th>\n",
       "      <th>midwest_inventory</th>\n",
       "      <th>midwest_change</th>\n",
       "      <th>mountain_inventory</th>\n",
       "      <th>mountain_change</th>\n",
       "      <th>pacific_inventory</th>\n",
       "      <th>pacific_change</th>\n",
       "      <th>south_central_inventory</th>\n",
       "      <th>south_central_change</th>\n",
       "      <th>salt_inventory</th>\n",
       "      <th>salt_change</th>\n",
       "      <th>nonsalt_inventory</th>\n",
       "      <th>nonsalt_change</th>\n",
       "      <th>HDDs</th>\n",
       "      <th>CDDs</th>\n",
       "      <th>TDDs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-17</th>\n",
       "      <td>2370</td>\n",
       "      <td>-163.0</td>\n",
       "      <td>566</td>\n",
       "      <td>-54.0</td>\n",
       "      <td>673</td>\n",
       "      <td>-56.0</td>\n",
       "      <td>121</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>185</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>823</td>\n",
       "      <td>-38.0</td>\n",
       "      <td>295</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>528</td>\n",
       "      <td>-29.0</td>\n",
       "      <td>199</td>\n",
       "      <td>0</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-24</th>\n",
       "      <td>2197</td>\n",
       "      <td>-173.0</td>\n",
       "      <td>527</td>\n",
       "      <td>-39.0</td>\n",
       "      <td>606</td>\n",
       "      <td>-67.0</td>\n",
       "      <td>114</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>178</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>771</td>\n",
       "      <td>-52.0</td>\n",
       "      <td>278</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>493</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-31</th>\n",
       "      <td>1960</td>\n",
       "      <td>-237.0</td>\n",
       "      <td>468</td>\n",
       "      <td>-59.0</td>\n",
       "      <td>522</td>\n",
       "      <td>-84.0</td>\n",
       "      <td>105</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>172</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>692</td>\n",
       "      <td>-79.0</td>\n",
       "      <td>241</td>\n",
       "      <td>-37.0</td>\n",
       "      <td>451</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-07</th>\n",
       "      <td>1882</td>\n",
       "      <td>-78.0</td>\n",
       "      <td>444</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>492</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>95</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>155</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>696</td>\n",
       "      <td>4.0</td>\n",
       "      <td>248</td>\n",
       "      <td>7.0</td>\n",
       "      <td>447</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>160</td>\n",
       "      <td>2</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-14</th>\n",
       "      <td>1705</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>395</td>\n",
       "      <td>-49.0</td>\n",
       "      <td>436</td>\n",
       "      <td>-56.0</td>\n",
       "      <td>87</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>138</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>649</td>\n",
       "      <td>-47.0</td>\n",
       "      <td>224</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>425</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            l48_inventory  l48_change  east_inventory  east_change  \\\n",
       "2019-01-17           2370      -163.0             566        -54.0   \n",
       "2019-01-24           2197      -173.0             527        -39.0   \n",
       "2019-01-31           1960      -237.0             468        -59.0   \n",
       "2019-02-07           1882       -78.0             444        -24.0   \n",
       "2019-02-14           1705      -177.0             395        -49.0   \n",
       "\n",
       "            midwest_inventory  midwest_change  mountain_inventory  \\\n",
       "2019-01-17                673           -56.0                 121   \n",
       "2019-01-24                606           -67.0                 114   \n",
       "2019-01-31                522           -84.0                 105   \n",
       "2019-02-07                492           -30.0                  95   \n",
       "2019-02-14                436           -56.0                  87   \n",
       "\n",
       "            mountain_change  pacific_inventory  pacific_change  \\\n",
       "2019-01-17             -6.0                185           -11.0   \n",
       "2019-01-24             -7.0                178            -7.0   \n",
       "2019-01-31             -9.0                172            -6.0   \n",
       "2019-02-07            -10.0                155           -17.0   \n",
       "2019-02-14             -8.0                138           -17.0   \n",
       "\n",
       "            south_central_inventory  south_central_change  salt_inventory  \\\n",
       "2019-01-17                      823                 -38.0             295   \n",
       "2019-01-24                      771                 -52.0             278   \n",
       "2019-01-31                      692                 -79.0             241   \n",
       "2019-02-07                      696                   4.0             248   \n",
       "2019-02-14                      649                 -47.0             224   \n",
       "\n",
       "            salt_change  nonsalt_inventory  nonsalt_change  HDDs  CDDs  TDDs  \n",
       "2019-01-17         -8.0                528           -29.0   199     0   199  \n",
       "2019-01-24        -17.0                493           -35.0   200     0   200  \n",
       "2019-01-31        -37.0                451           -42.0   229     0   229  \n",
       "2019-02-07          7.0                447            -4.0   160     2   162  \n",
       "2019-02-14        -24.0                425           -22.0   191     1   192  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Create the SQL database**\n",
    "\n",
    "**Create a connection to a local SQLite database**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('sqlite:///storage.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create the storage_weather table in the database**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Base.metadata.create_all(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use a Session object to push the objects created and query the server**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy.orm import Session\n",
    "session = Session(bind=engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finally, save the DataFrame as a local .db file**\n",
    "\n",
    "_after creating a database schema_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_dict = {'l48_inventory' : Float(),\n",
    "               'l48_change' : Float(),\n",
    "               'east_inventory' : Float(),\n",
    "               'east_change' : Float(),\n",
    "               'midwest_inventory' : Float(),\n",
    "               'midwest_change' : Float(),\n",
    "               'mountain_inventory' : Float(),\n",
    "               'mountain_change' : Float(),\n",
    "               'pacific_inventory' : Float(),\n",
    "               'pacific_change' : Float(),\n",
    "               'south_central_inventory' : Float(),\n",
    "               'south_central_change' : Float(),\n",
    "               'salt_inventory' : Float(),\n",
    "               'salt_change' : Float(),\n",
    "               'nonsalt_inventory' : Float(),\n",
    "               'nonsalt_change' : Float(),\n",
    "               'HDDs' : Float(),\n",
    "               'CDDs' : Float(),\n",
    "               'TDDs' : Float()\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_sql('storage_weather', dtype = schema_dict, con = engine, index_label = 'week', if_exists = 'replace')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
