{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Gas Storage and Temperature Outcomes\n",
    "\n",
    "This script pulls publicly available US temperature data and reported US natural gas storage activity, merges/formats that data using pandas DataFrames, and pushes the merged data to a SQL database\n",
    "\n",
    "Data is collected from the [Energy Information Administration's API](https://www.eia.gov/opendata/)\n",
    "and Climate Prediction Center's [FTP Site](ftp://ftp.cpc.ncep.noaa.gov/htdocs/degree_days/weighted/daily_data/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import dependencies:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import datetime\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Establish API key and organize a dictionary of API series id's for each storage region:**\n",
    "_The EIA API series IDs used in this analysis are listed [here](https://www.eia.gov/opendata/qb.php?category=1709237)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "eia_api_key = '9e4c8d5761a387405ed003e062d45727'\n",
    "\n",
    "#this dictionary is a repository for the unique series ids for the Lower 48 and each EIA sub-region\n",
    "#... the regional keys established here are also referenced to establish dictionaries for the API calls and DataFrame conversions\n",
    "eia_api_series_ids = {\n",
    "    'l48' : 'NG.NW2_EPG0_SWO_R48_BCF.W',\n",
    "    'east' : 'NG.NW2_EPG0_SWO_R31_BCF.W',\n",
    "    'midwest' : 'NG.NW2_EPG0_SWO_R32_BCF.W',\n",
    "    'mountain' : 'NG.NW2_EPG0_SWO_R34_BCF.W',\n",
    "    'pacific' : 'NG.NW2_EPG0_SWO_R35_BCF.W',\n",
    "    'south_central' : 'NG.NW2_EPG0_SWO_R33_BCF.W',\n",
    "    'salt' : 'NG.NW2_EPG0_SSO_R33_BCF.W',\n",
    "    'nonsalt': 'NG.NW2_EPG0_SNO_R33_BCF.W'\n",
    "}\n",
    "\n",
    "#establishes base url for each API call\n",
    "#you just need to combine with the API ID string to complete each call\n",
    "base_url = f'http://api.eia.gov/series/?api_key={eia_api_key}&series_id='\n",
    "\n",
    "#establish empty dictionaries that will be used to save API calls and DataFrames\n",
    "call_dict = {}\n",
    "df_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create API calls:**\n",
    "\n",
    "_using a function that iterates through the regional names established in the keys for the eia_api_series_ids dictionary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_call(n):\n",
    "    return json.loads(requests.get(base_url + eia_api_series_ids[n]).text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in eia_api_series_ids:\n",
    "    call_dict[n] = generate_call(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert JSON data from the API calls to pandas DataFrames**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_df(call):\n",
    "   return pd.DataFrame(call['series'][0]['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in call_dict:\n",
    "    df_dict[n] = generate_df(call_dict[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Format the regional DataFrames**\n",
    "1. _name columns_\n",
    "2. _convert 'week' column to datetime format_\n",
    "3. _set the index to 'week'_\n",
    "4. calculate week-over-week inventory change for each week\n",
    "5. _subtract 1 day from the weekly index date, to reflect the actual end date of each 'gas week'_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_df(n):\n",
    "    df_dict[n].columns=['week',f'{n}_inventory']\n",
    "    df_dict[n]['week'] = pd.to_datetime(df_dict[n]['week'])\n",
    "    df_dict[n] = df_dict[n].sort_values('week')\n",
    "    df_dict[n] = df_dict[n].set_index('week')\n",
    "    df_dict[n][f'{n}_change'] = df_dict[n][f'{n}_inventory'] - df_dict[n][f'{n}_inventory'].shift(1)\n",
    "    df_dict[n].index = df_dict[n].index - datetime.timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in df_dict:\n",
    "    format_df(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "eia_storage_data = df_dict['l48'].merge(\n",
    "    df_dict['east'], left_index = True, right_index = True).merge(\n",
    "    df_dict['midwest'], left_index = True, right_index = True).merge(\n",
    "    df_dict['mountain'], left_index = True, right_index = True).merge(\n",
    "    df_dict['pacific'], left_index = True, right_index = True).merge(\n",
    "    df_dict['south_central'], left_index = True, right_index = True).merge(\n",
    "    df_dict['salt'], left_index = True, right_index = True).merge(\n",
    "    df_dict['nonsalt'], left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Weather Data Pull**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pull HDDs**\n",
    "\n",
    "*add note on HDD definition*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ = []\n",
    "for x in range(1981,datetime.datetime.now().year+1):\n",
    "    df = pd.read_csv(f'ftp://ftp.cpc.ncep.noaa.gov/htdocs/degree_days/weighted/daily_data/{x}/Population.Heating.txt',skiprows = 3, delimiter = '|').T\n",
    "    df.drop(df.index[0], inplace = True)\n",
    "    list_.append(df)\n",
    "CPC_HDDs = pd.concat(list_)\n",
    "CPC_HDDs.index = pd.to_datetime(CPC_HDDs.index)\n",
    "CPC_HDDs = CPC_HDDs[9]\n",
    "CPC_HDDs = pd.DataFrame(CPC_HDDs)\n",
    "CPC_HDDs.columns = ['HDDs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pull CDDs**\n",
    "\n",
    "*add note on CDD definition*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ = []\n",
    "for x in range(1981,datetime.datetime.now().year+1):\n",
    "    df = pd.read_csv(f'ftp://ftp.cpc.ncep.noaa.gov/htdocs/degree_days/weighted/daily_data/{x}/Population.Cooling.txt',skiprows = 3, delimiter = '|').T\n",
    "    df.drop(df.index[0], inplace = True)\n",
    "    list_.append(df)\n",
    "CPC_CDDs = pd.concat(list_)\n",
    "CPC_CDDs.index = pd.to_datetime(CPC_CDDs.index)\n",
    "CPC_CDDs = CPC_CDDs[9]\n",
    "CPC_CDDs = pd.DataFrame(CPC_CDDs)\n",
    "CPC_CDDs.columns = ['CDDs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Combine degree day data into a single datagrame**\n",
    "\n",
    "...and add a Total Degree Day (TDDs) column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "CPC_TDDs = pd.merge(CPC_HDDs,CPC_CDDs, left_index = True, right_index = True)\n",
    "CPC_TDDs['TDDs'] = CPC_TDDs['HDDs'] + CPC_TDDs['CDDs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resample temperature data to report sum of degree days for each week ending Thursday**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "CPC_TDDs_Weekly = CPC_TDDs.resample('W-Thu').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finally, combine all temperature and storage data into a single DataFrame**\n",
    "\n",
    "... _and convert all columns to integers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.merge(eia_storage_data,CPC_TDDs_Weekly, left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in combined_df.columns:\n",
    "    combined_df[n] = pd.to_numeric(combined_df[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
